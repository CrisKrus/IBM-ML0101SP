{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width = 400, align = \"center\"></a>\n",
    "# <center>Análisis de Regresión no Lineal</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si los datos muestran tendencias curas, entonces la regresión lineal no producirá resultados muy exactos cuando se comparan con una regresión no lineal, porque, como su nombre lo indica, la regresión lineal sume que los datos son lineales. \n",
    "Aprendamos sobre regresiones no lineales y apliquemos un ejemplo en python. En este lab, conectaremos un modelo no lineal con los puntos de tendencia correspondientes al GDP de China entre los años 1960 y 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando las librerías requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque la regresión lineal es muy buena para resolver varios problemas, no puede utilizarse en todos los sets de datos. Primero, recordemos cómo funciona la regresión lineal, se podría modelar un set de datos. Modelar una relación lineal entre una variable dependiente y una variable independiente x, tendría una simple ecuación de grado 1, por ejemplo y = 2*(x) + 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "\n",
    "##Se puede ajustar la pendiente y la intersección para verificar los cambios en el gráfico\n",
    "y = 2*(x) + 3\n",
    "y_noise = 2 * np.random.normal(size=x.size)\n",
    "ydata = y + y_noise\n",
    "#plt.figure(figsize=(8,6))\n",
    "plt.plot(x, ydata,  'bo')\n",
    "plt.plot(x,y, 'r') \n",
    "plt.ylabel('Variable dependiente')\n",
    "plt.xlabel('Variable independiente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las regresiones no-lineales son una relación entre variables independientes $x$ y una variable dependiente $y$ que resulta en una función no lineal. Básicamente, cada relación que no es lineal puede transformarse en una no lineal, y generalmente se representa con el polinomio de grados $k$ (potencia máxima de $x$). \n",
    "\n",
    "$$ \\ y = a x^3 + b x^2 + c x + d \\ $$\n",
    "\n",
    "Las funciones no lineales pueden tener elementos como exponentes, logaritmos, fracciones y otros. Por ejemplo: $$ y = \\log(x)$$\n",
    "    \n",
    "O más complicados, como :\n",
    "$$ y = \\log(a x^3 + b x^2 + c x + d)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miremos el gráfico de la función cúbica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "\n",
    "##Puede ajustar la pendiente y la intersección para verificar los cambios del gráfico\n",
    "y = 1*(x**3) + 1*(x**2) + 1*x + 3\n",
    "y_noise = 20 * np.random.normal(size=x.size)\n",
    "ydata = y + y_noise\n",
    "plt.plot(x, ydata,  'bo')\n",
    "plt.plot(x, y, 'r')\n",
    "plt.ylabel('Variable dependiente')\n",
    "plt.xlabel('Variable indepdendiente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, esta función tiene $x^3$ y $x^2$ como variables independientes. También, el gráfico de esta función no es una linea directa, por lo que es una función no lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas otras funciones no lineales son:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuadrática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Y = X^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "\n",
    "##Se puede ajustar la pendiente y la intersección para verificar los cambios en el gráfico\n",
    "\n",
    "y = np.power(x,2)\n",
    "y_noise = 2 * np.random.normal(size=x.size)\n",
    "ydata = y + y_noise\n",
    "plt.plot(x, ydata,  'bo')\n",
    "plt.plot(x,y, 'r') \n",
    "plt.ylabel('Variable dependiente')\n",
    "plt.xlabel('Variable indepdiendente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponencial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una función exponencial con base c se define por $$ Y = a + b c^X$$ donde b ≠0, c > 0 , c ≠1, y x es cualquier número real. La base, c, es constante y el exponente, x, es una variable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.arange(-5.0, 5.0, 0.1)\n",
    "\n",
    "##Se puede ajustar la pendiente y la intersección para verificar los cambios en el gráfico\n",
    "\n",
    "Y= np.exp(X)\n",
    "\n",
    "plt.plot(X,Y) \n",
    "plt.ylabel('Variable Dependiente')\n",
    "plt.xlabel('Variable Independiente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarítmico\n",
    "\n",
    "La respuesta $y$ es el resultado de aplicar el mapa logarítmico desde el valor de entrada de $x$ a la variable de salida $y$. Es una de las formas más simples de __log()__: i.e. $$ y = \\log(x)$$\n",
    "\n",
    "Favor, considerar que en vez de $x$, podemos usar $X$, el cual puede ser una representación polinomial de las $x$'s. En su forma general, se escribiría como  \n",
    "\\begin{equation}\n",
    "y = \\log(X)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.arange(-5.0, 5.0, 0.1)\n",
    "\n",
    "Y = np.log(X)\n",
    "\n",
    "plt.plot(X,Y) \n",
    "plt.ylabel('Variable Dependiente')\n",
    "plt.xlabel('Variable Independiente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoidal/Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Y = a + \\frac{b}{1+ c^{(X-d)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(-5.0, 5.0, 0.1)\n",
    "\n",
    "\n",
    "Y = 1-4/(1+np.power(3, X-2))\n",
    "\n",
    "plt.plot(X,Y) \n",
    "plt.ylabel('Variable Dependiente')\n",
    "plt.xlabel('Variable Independiente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "# Ejemplo de Regresión No-Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, intentaremos fijar un modelo no lineal a los puntos correspondientes al GDP de China entre los años 1960 y 2014. Descargaremos un set de datos con dos columnas, la primera, un año entre 1960 y 2014, la segunda, el ingreso anual de China en dólares estadounidenses para ese año. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#downloading dataset\n",
    "!wget -nv -O china_gdp.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/china_gdp.csv\n",
    "    \n",
    "df = pd.read_csv(\"china_gdp.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Sabías?__ Cuando se trata de Machine Learning, seguro trabajarás con grandes datasets (juego de datos). Entonces, ¿dónde podrás guardar esos datos? IBM ofrece una oportunidad única para las empresas, con 10 Tb de IBM Cloud Object Storage: [Registrate ahora gratuitamente](http://cocl.us/ML0101EN-IBM-Offer-CC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marcando el set de datos ###\n",
    "Asi es como los puntos de datos se ven. Se parece a una función lógica o exponencial. El crecimiento es leve, luego a partir de 2005 en adelante, el crecimiento ya es más notorio. Y finalmente, desacelera suavemente a principio del año 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "x_data, y_data = (df[\"Year\"].values, df[\"Value\"].values)\n",
    "plt.plot(x_data, y_data, 'ro')\n",
    "plt.ylabel('GDP')\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eligiendo un modelo ###\n",
    "\n",
    "A primera vista, determinamos que la función lógica podría ser una buena primera aproximación,\n",
    "ya que tiene la propiedad de comenzar con un crecimiento leve, aumentando en el medio y luego descendiendo nuevamente hacia el final; como se ve debajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.arange(-5.0, 5.0, 0.1)\n",
    "Y = 1.0 / (1.0 + np.exp(-X))\n",
    "\n",
    "plt.plot(X,Y) \n",
    "plt.ylabel('Variable Dependiente')\n",
    "plt.xlabel('Variable Independiente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "La fórumla para la función logística es la siguiente:\n",
    "\n",
    "$$ \\hat{Y} = \\frac1{1+e^{\\beta_1(X-\\beta_2)}}$$\n",
    "\n",
    "$\\beta_1$: Controla lo llano de la curva,\n",
    "\n",
    "$\\beta_2$: Lleva la curva sobre el eje x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo el Modelo ###\n",
    "Ahora, construyamos nuestro modelo de regresión e inicialicemos sus parámetros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, Beta_1, Beta_2):\n",
    "     y = 1 / (1 + np.exp(-Beta_1*(x-Beta_2)))\n",
    "     return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, un ejemplo sigmoide que podría cuadrar con los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "beta_1 = 0.10\n",
    "beta_2 = 1990.0\n",
    "\n",
    "#función logística\n",
    "Y_pred = sigmoid(x_data, beta_1 , beta_2)\n",
    "\n",
    "#predicción de puntos\n",
    "plt.plot(x_data, Y_pred*15000000000000.)\n",
    "plt.plot(x_data, y_data, 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra tarea aquí es encontrar los mejores parámetros para nuestro modelo. Normalicemos primero nuestro x e y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalicemos nuestros datos\n",
    "xdata =x_data/max(x_data)\n",
    "ydata =y_data/max(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cómo podemos encontrar los mejores parámetros para nuestra linea?\n",
    "podemos utilizar __curve_fit__ la cual utiliza cuadrados mínimos no lineales para cuadrar con la función sigmoide. Los valores óptimos para los parámetros que suman los residuos cuadrados de sigmoid(xdata, *popt) - ydata minimizado.\n",
    "\n",
    "popt son nuestros parámetros optimizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "popt, pcov = curve_fit(sigmoid, xdata, ydata)\n",
    "#imprimir los parámetros finales\n",
    "print(\" beta_1 = %f, beta_2 = %f\" % (popt[0], popt[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora dibujamos nuestro modelo de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1960, 2015, 55)\n",
    "x = x/max(x)\n",
    "plt.figure(figsize=(8, 5))\n",
    "y = sigmoid(x, *popt)\n",
    "plt.plot(xdata, ydata, 'ro', label='data')\n",
    "plt.plot(x, y, linewidth=3.0, label='fit')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('GDP')\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica\n",
    "¿Puedes calcular cual es la exactitud de nuestro modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "## MI SOLUCION ##\n",
    "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y - ydata)))\n",
    "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((y - ydata) ** 2))\n",
    "print(\"R2-score: %.2f\" % r2_score(y, ydata))\n",
    "\n",
    "## SOLUCION PROPUESTA ##\n",
    "# divide los datos en entrenamiento y prueba\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train_x = xdata[msk]\n",
    "test_x = xdata[~msk]\n",
    "train_y = ydata[msk]\n",
    "test_y = ydata[~msk]\n",
    "\n",
    "# construye el modelo utilizando el set de entrenamiento\n",
    "popt, pcov = curve_fit(sigmoid, train_x, train_y)\n",
    "\n",
    "# predecir utilizando el set de prueba\n",
    "y_hat = sigmoid(test_x, *popt)\n",
    "\n",
    "# evaluation\n",
    "print(\"Promedio de error absoluto: %.2f\" % np.mean(np.absolute(y_hat - test_y)))\n",
    "print(\"Suma residual de cuadrados (MSE): %.2f\" % np.mean((y_hat - test_y) ** 2))\n",
    "print(\"R2-score: %.2f\" % r2_score(y_hat, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haz doble click __aquí__ para la solución.\n",
    "\n",
    "<!-- Tu respuesta debajo:\n",
    "    \n",
    "# divide los datos en entrenamiento y prueba\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train_x = xdata[msk]\n",
    "test_x = xdata[~msk]\n",
    "train_y = ydata[msk]\n",
    "test_y = ydata[~msk]\n",
    "\n",
    "# construye el modelo utilizando el set de entrenamiento\n",
    "popt, pcov = curve_fit(sigmoid, train_x, train_y)\n",
    "\n",
    "# predecir utilizando el set de prueba\n",
    "y_hat = sigmoid(test_x, *popt)\n",
    "\n",
    "# evaluation\n",
    "print(\"Promedio de error absoluto: %.2f\" % np.mean(np.absolute(y_hat - test_y)))\n",
    "print(\"Suma residual de cuadrados (MSE): %.2f\" % np.mean((y_hat - test_y) ** 2))\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2-score: %.2f\" % r2_score(y_hat , test_y) )\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Deseas aprender más?\n",
    "\n",
    "IBM SPSS Modeler es una plataforma para analytics que contiene varios algoritmos de machine learning. Fue diseñada para acercar inteligencia predictiva a las decisiones hechas por individuos, grupos, sistemas, toda la empresa. Un free trial está disponible a través de este curso en: [SPSS Modeler](http://cocl.us/ML0101EN-SPSSModeler).\n",
    "\n",
    "Asi mismo, puedes utilizar Watson Studio para ejecutar estos notebooks más rápido y con datasets más grandes. Watson Studio es una solución en la nube lider de IBM's para científicos de datos, construída por científicos de datos. Con Jupyter notebooks, RStudio, Apache Spark y librerías conocidas pre instaladas en la nube, Watson Studio posibilita a los científicos de datos colaborar en sus proyectos sin tener que instalar nada. Sumate a la comunidad de usuarios Watson Studio hoy mismo por medio de una cuenta gratuita en [Watson Studio](https://cocl.us/ML0101EN_DSX)\n",
    "\n",
    "### ¡Gracias por completar esta lección!\n",
    "\n",
    "Notebook creado por: <a href = \"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>\n",
    "\n",
    "<hr>\n",
    "Copyright &copy; 2018 [Cognitive Class](https://cocl.us/DX0108EN_CC). Este lab y su código fuente fueron registrados bajo los términos de [MIT License](https://bigdatauniversity.com/mit-license/).​"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
