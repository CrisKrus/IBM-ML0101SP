{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width = 400, align = \"center\"></a>\n",
    "\n",
    "<h1 align=center><font size = 5> Regresi√≥n Log√≠stica con Python</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Aqu√≠ aprender√°s Regresi√≥n Log√≠stica, para luego, crear un modelo basado en datos de telecomunicaciones para predecir cu√°ndo los clientes buscar√°n otro competidor de forma tal de poder tomar alguna decisi√≥n para retenerlos.\n",
    "\n",
    "\n",
    "<a id=\"ref1\"></a>\n",
    "## ¬øCu√°l es la diferencia entre Regresi√≥n Log√≠stica y Regresi√≥n Lineal?\n",
    "\n",
    "Mientras la Regresi√≥n Lineal es para estimar valores continuos (ej. estimar precios de casas), no es la mejor herramienta para predecir la clase de un punto de datos observados. Para estimar la clase de punto de datos, necesitaremos una gu√≠a de lo que ser√≠a la **clase m√°s probable** para ese punto de datos. Por esto, utilizamos **Regresi√≥n Log√≠stica**.\n",
    "\n",
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "<font size = 3><strong>Regresi√≥n Lineal:</strong></font>\n",
    "<br>\n",
    "<br>\n",
    "Como sabes, la __Regresi√≥n lineal__ encuentra una funci√≥n que relaciona una variable continua dependiente, _y_, con algunos predictores (variables independientes _x1_, _x2_, etc.). Por ejemplo, la regresi√≥n lineal Simple asume una funci√≥n de la forma:\n",
    "<br><br>\n",
    "$$\n",
    "y = ùúÉ0 + ùúÉ1 * x1 + ùúÉ2 * x2 +...\n",
    "$$\n",
    "<br>\n",
    "y encuentra los valores de los par√°metros _Œ∏0_, _Œ∏1_, _ùúÉ2_, etc, donde el t√©rmino _ùúÉ0_ es \"intersecci√≥n\". Generalmente se muestra como:\n",
    "<br><br>\n",
    "$$\n",
    "‚Ñé_Œ∏(ùë•) = ùúÉ^TX\n",
    "$$\n",
    "<p></p>\n",
    "\n",
    "</div>\n",
    "\n",
    "La Regresion Log√≠stica es una variaci√≥n de una Regresi√≥n Lineal, √∫til cuando la variable dependiente observada, _y_, es categ√≥rica. Produce una f√≥rmula que predice la probabilidad de la clase etiqueta como una funci√≥n de las variables independientes.\n",
    "\n",
    "La regresi√≥n log√≠stica es una curva especial en forma de s a partir de tomar la regresi√≥n lineal y transformar la estimaci√≥n num√©rica en una probabilidad con la siguiente funci√≥n, llamada sigmoide ùúé:\n",
    "\n",
    "$$\n",
    "‚Ñé_Œ∏(ùë•) = ùúé({Œ∏^TX}) =  \\frac {e^{(Œ∏0 + Œ∏1 * x1 + Œ∏2 * x2 +...)}}{1 + e^{(Œ∏0 + Œ∏1 * x1 + Œ∏2 * x2 +...)}}\n",
    "$$\n",
    "Or:\n",
    "$$\n",
    "ProbabilityOfaClass_1 =  P(Y=1|X) = ùúé({Œ∏^TX}) = \\frac{e^{Œ∏^TX}}{1+e^{Œ∏^TX}} \n",
    "$$\n",
    "\n",
    "En esta ecuaci√≥n, ${Œ∏^TX}$ es el resultado de la regresi√≥n (la suma de las variables ponderadas por los coeficientes), `exp` es la funci√≥n exponencial y $ùúé(Œ∏^TX)$ es la funci√≥n sigmoide √≥ [funci√≥n log√≠stica](http://en.wikipedia.org/wiki/Logistic_function), tambi√©n llamada curva log√≠stica. Tiene una forma de \"S\" (curva sigmoide).\n",
    "\n",
    "En resumen, la Regresi√≥n Log√≠stica pasa la entrada a trav√©s de las funciones log√≠stica/sigmoide pero en realidad termina tratando al resultado como una probabilidad:\n",
    "\n",
    "<img\n",
    "src=\"https://ibm.box.com/shared/static/kgv9alcghmjcv97op4d6onkyxevk23b1.png\" width = \"400\" align = \"center\">\n",
    "\n",
    "\n",
    "El objetivo del algoritmo de __Regresi√≥n Log√≠stica__, es encontrar los mejores par√°metros Œ∏, para ‚Ñé_Œ∏(ùë•) = ùúé({Œ∏^TX}), de forma tal de que el modelo prediga lo mejor posible la clase de cada caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cliente churn con Regresi√≥n Log√≠stica\n",
    "Una compa√±√≠a de telecomunicaciones est√° preocupada por el n√∫mero de clientes que dejan sus l√≠neas fijas de negocio por las de competidores de cable. Ellos necesitan entender qui√©n se est√° yendo. Imagina que eres un analista en esta compa√±√≠a y que tienes que descubrir qui√©n es el cliente que se va y por qu√©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Primero, importemos las librer√≠as necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Acerca del set de datos\n",
    "Utilizaremos datos de las telecomunicaciones para poder predecir el cliente churn. Estos son datos hist√≥ricos de clientes donde cada fila representa un cliente. Los datos son f√°ciles de comprender, y podr√°s descubrir conclusiones que puedes usar de inmediato. Generalmente, es menos caro mantener clientes que conseguir nuevos, as√≠ que el foco de este an√°lisis es predecir los clientes que se quedar√≠an en la compa√±√≠a. \n",
    "\n",
    "\n",
    "Estos datos proveen informaci√≥n que ayudar√°n a predecir comportamientos que retendr√°n a los clientes. Puedes analizar toda la informaci√≥n relevante del cliente y desarrollar programas de retenci√≥n centrados en los clientes.\n",
    "\n",
    "\n",
    "\n",
    "Los datos incluyen informaci√≥n acerca de:\n",
    "\n",
    "- Clientes que se fueron el √∫ltimo mes ‚Äì la columna se llama Churn\n",
    "- Los servicios que cada cliente ha contratado ‚Äì tel√©fono, l√≠neas m√∫ltiples, internet, seguridad online, resguardo online, protecci√≥n de dispositivos, soporte t√©cnico y streaming de TV y pel√≠culas\n",
    "- Informaci√≥n de la cuenta del cliente - cu√°nto hace que es cliente, contrato, m√©todo de pago, facturaci√≥n digital, cargos mensuales y cargos totales\n",
    "- Informaci√≥n demogr√°fica de los clientes ‚Äì sexo, rango de edad y si tienen pareja y dependientes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "###  Cargar los datos Churn de la Telco \n",
    "Telco Churn es un archivo de datos ficticio que trata sobre los esfuerzos de una compa√±√≠a de telecomunicaciones para reducir la hu√≠da de sus clientes. Cada caso corresponde a un cliente y se guarda informaci√≥n demogr√°fica e informaci√≥n referente al uso del servicio. Antes de trabajar con los datos, debes utilizar la URL para obtener el archivo ChurnData.csv.\n",
    "\n",
    "Para descargarlo, utilizaremos `!wget` desde IBM Object Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Hacer click aqu√≠ y presionar Shift+Enter\n",
    "!wget -O ChurnData.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/ChurnData.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¬øSab√≠as?__ Cuando se trata de Machine Learning, seguro trabajar√°s con grandes datasets (juego de datos). Entonces, ¬ød√≥nde podr√°s guardar esos datos? IBM ofrece una oportunidad √∫nica para las empresas, con 10 Tb de IBM Cloud Object Storage: [Sign up now for free](http://cocl.us/ML0101EN-IBM-Offer-CC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Cargar los Datos desde el Archivo CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "churn_df = pd.read_csv(\"ChurnData.csv\")\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecci√≥n y pre-procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionemos algunas caracter√≠sticas para el modelado. Tambi√©n cambiemos el tipo de dato del objetivo (target) para que sea un n√∫mero entero (integer), ya que es un requerimiento del algoritmo skitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n",
    "churn_df['churn'] = churn_df['churn'].astype('int')\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": true,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Pr√°ctica\n",
    "¬øCu√°ntas filas y columnas en total hay en este set de datos? ¬øCual es el nombre de las columnas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# escrib√≠ tu c√≥digo aqu√≠\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos X, e y para nuestro set de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(churn_df['churn'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi√©n, normalicemos el set de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar/Probar el set de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, dividamos nuestro set de datos en dos sets, entrenamiento y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelando (Regresi√≥n Log√≠stica con Scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construyamos nuestro modelo utilizando __LogisticRegression__ con el package Scikit-learn. Esta funci√≥n implementa regresi√≥n log√≠stica y puede usar distintos optimizadores num√©ricos para encontrar par√°metros, a saber, ‚Äònewton-cg‚Äô, ‚Äòlbfgs‚Äô, ‚Äòliblinear‚Äô, ‚Äòsag‚Äô, ‚Äòsaga‚Äô solvers. Puedes tambi√©n encontrar m√°s informaci√≥n sobre los pros y contras de estos optimizadores si buscas en internet.\n",
    "\n",
    "La versi√≥n de Regresi√≥n Log√≠stica en, soporta regularizaci√≥n. Esto es, una t√©cnica que soluciona problemas de sobreajuste en modelos de machine learning.\n",
    "El par√°metro __C__ indica __fuerza de regularizaci√≥n inversa__ la cual debe ser un n√∫mero flotante positivo. Valores m√°s peque√±os indican regularizaci√≥n m√°s fuerte. \n",
    "Now lets fit our model with train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podremos predecir usando nuestro set de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__predict_proba__  devuelve estimaciones para todas las clases. La primer columna es la probabilidad de la clase 1, P(Y=1|X), y la segunda columna es la probabilidad de la clase 0, P(Y=0|X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### √≠ndice jaccard\n",
    "Probemos con el √≠ndice jaccard para la evaluaci√≥n de precisi√≥n. Podemos definir como jaccard al tama√±o de la intersecci√≥n dividida por el tama√±o de la uni√≥n de dos set de etiquetas. Si todo el set de etiquetas de muestra predichas coinciden con el set real de etiquetas, entonces la precisi√≥n es 1.0; sino, ser√≠a 0.0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusi√≥n\n",
    "Otra forma de mirar la precisi√≥n del clasificador es ver la __matriz de confusi√≥n__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Esta funci√≥n muestra y dibuja la matriz de confusi√≥n.\n",
    "    La normalizaci√≥n se puede aplicar estableciendo el valor `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Matriz de confusi√≥n normalizada\")\n",
    "    else:\n",
    "        print('Matriz de confusi√≥n sin normalizaci√≥n')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta Real')\n",
    "    plt.xlabel('Etiqueta Predicha')\n",
    "print(confusion_matrix(y_test, yhat, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de confusi√≥n\n",
    "cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Dibujar la matriz de confusi√≥n no normalizada\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Matriz de confusi√≥n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa la primer fila. Ah√≠ est√°n los clientes cuyo valor churn en el set de prueba es 1.\n",
    "Como podr√°s calcular, de 40 clientes, el valor churn de 15 de ellos es 1. \n",
    "Y de otros 15, el clasificador predijo que 6 de ellos son 1 y 9 0. \n",
    "\n",
    "Quiere decir que, para 6 clientes, el valor actual de churn fue 1 en el set de pruebas y el clasificador los predijo correctamente como 1. Sin embargo, mientras la etiqueta actual de 9 clientes era 1, el clasificador los predijo como 0, lo cual no es muy bueno. Lo podemos considerar como un error del modelo para la primer fila.\n",
    "\n",
    "¬øQu√© pasa con los clientes con valor churn 0? Miremos la segunda fila.\n",
    "Parece que hay 25 clientes con valor churn 0. \n",
    "\n",
    "\n",
    "El clasificador predijo correctamente 24 de ellos como 0 y uno de ellos equivocadamente como 1. As√≠ que ha hecho un buen trabajo prediciendo los clientes con churn 0. Una ventaja de la matriz de confusi√≥n es que muestra la abilidad del modelo para correctamente predecir o separar las clases. En el caso de clasificador binario, como el ejemplo, podemos entender a estos n√∫meros como la cantidad de positivos verdaderos, negativos verdaderos y negativos falsos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test, yhat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiendo de la cantidad de cada secci√≥n podemos calcular la precisi√≥n y el grado(recall) de cada etiqueta:\n",
    "\n",
    "\n",
    "- __Precision__ es una medida de certeza basada en una etiqueta predicha. Se define de esta forma: precision = TP¬†/¬†(TP¬†+¬†FP)\n",
    "\n",
    "- __Recall__ es un grado positivo verdadero. Se define de esta forma: Recall = ¬†TP¬†/¬†(TP¬†+¬†FN)\n",
    "\n",
    "    \n",
    "Por lo tanto, podemos calcular la precisi√≥n y grado de cada clase.\n",
    "\n",
    "__F1 score:__\n",
    "Ahora estamos en condiciones de calcular los puntajes F1 para cada etiqueta basada en la precisi√≥n y grado de cada etiqueta. \n",
    "\n",
    "El puntaje F1 es el promedio arm√≥nico de la precisi√≥n y grado, donde un grado F1¬†alcanza su mejor valor en 1 (precisi√≥n y grado perfectos) y peor escenario en 0. Es una buena forma de mostrar que un clasificador tiene un buen valor tanto para la precisi√≥n como para el grado.\n",
    "\n",
    "\n",
    "Y finalmente, podemos decir que la exactitud promedio para este clasificador es el promedio del score f1 para ambas etiquetas, cuyo valor es is 0.72 en nuestro caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log loss\n",
    "Ahora, probemos __log loss__ para la evaluaci√≥n. En regresi√≥n log√≠stica, la salida puede ser que la probabilidad de cliente churn sea s√≠ (o su equivalente 1). Esta probabilidad es un valor entre 0 y 1.\n",
    "Log loss(¬†p√©rdida logar√≠tmica) mida el rendimiento de un clasificador donde la salida predicha es una probabilidad de valor entre 0 y 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, yhat_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "Intentaremos construir el modelo de Regresi√≥n Log√≠stica de nuevo para el mismo set de datos, pero esta vez, utilizando valores diferentes de __solucionador__ y __regularizaci√≥n__. ¬øCu√°l es el nuevo valor de __logLoss__ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribir tu c√≥digo aqu√≠\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer doble click __aqu√≠__ para la soluci√≥n.\n",
    "\n",
    "<!-- Tu respuesta est√° debajo:\n",
    "    \n",
    "LR2 = LogisticRegression(C=0.01, solver='sag').fit(X_train,y_train)\n",
    "yhat_prob2 = LR2.predict_proba(X_test)\n",
    "print (\"LogLoss: : %.2f\" % log_loss(y_test, yhat_prob2))\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## ¬øDeseas aprender m√°s?\n",
    "\n",
    "IBM SPSS Modeler es una plataforma para analytics que contiene varios algoritmos de machine learning. Fue dise√±ada para acercar inteligencia predictiva a las decisiones hechas por individuos, grupos, sistemas, toda la empresa. Un free trial est√° disponible a trav√©s de este curso en: [SPSS Modeler](http://cocl.us/ML0101EN-SPSSModeler).\n",
    "\n",
    "Asi mismo, puedes utilizar Watson Studio para ejecutar estos notebooks m√°s r√°pido y con datasets m√°s grandes. Watson Studio es una soluci√≥n en la nube lider de IBM's para cient√≠ficos de datos, constru√≠da por cient√≠ficos de datos. Con Jupyter notebooks, RStudio, Apache Spark y librer√≠as conocidas pre instaladas en la nube, Watson Studio posibilita a los cient√≠ficos de datos colaborar en sus proyectos sin tener que instalar nada. Sumate a la comunidad de usuarios Watson Studio hoy mismo por medio de una cuenta gratuita en [Watson Studio](https://cocl.us/ML0101EN_DSX)\n",
    "\n",
    "### ¬°Gracias por completar esta lecci√≥n!\n",
    "\n",
    "Laboratorio creado por: <a href = \"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>\n",
    "\n",
    "<hr>\n",
    "Copyright &copy; 2018 [Cognitive Class](https://cocl.us/DX0108EN_CC). Este lab y su c√≥digo fuente fueron registrados bajo los t√©rminos de [MIT License](https://bigdatauniversity.com/mit-license/).‚Äã"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
